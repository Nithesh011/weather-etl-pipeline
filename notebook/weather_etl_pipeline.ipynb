{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "54puZsIppwnM",
        "outputId": "b45730e0-6aa7-484c-c692-388617408b37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio<2.0.0,>=1.33.2->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (4.15.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark requests google-cloud-storage google-cloud-bigquery\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayHHhIqHp8w4",
        "outputId": "8ecc0769-3da7-4863-d45c-f841d7d96ba7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted and saved to GCS: weather_raw_2025-10-25.json\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "from google.cloud import storage\n",
        "from datetime import datetime,timedelta\n",
        "yesterday=datetime.now()-timedelta(days=1)\n",
        "yesterday_date = yesterday.strftime('%Y-%m-%d')\n",
        "latitude=19.07\n",
        "longitude=72.88\n",
        "timezone=\"Asia/Kolkata\"\n",
        "api_url = f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&hourly=temperature_2m,precipitation&start_date={yesterday_date}&end_date={yesterday_date}&timezone={timezone}\"\n",
        "result=requests.get(api_url)\n",
        "if result.status_code==200:\n",
        "  data=result.json()\n",
        "  with open(f\"weather_date-{yesterday_date}.json\",\"w\")as f:\n",
        "    json.dump(data,f,indent=2)\n",
        "    client = storage.Client.from_service_account_json('you-key ')  # Replace with your local key path\n",
        "    bucket = client.get_bucket('your-bucket')  # Replace with your bucket\n",
        "    blob_name = f'weather_raw_{datetime.now().strftime(\"%Y-%m-%d\")}.json'\n",
        "    blob = bucket.blob(blob_name)\n",
        "    blob.upload_from_string(json.dumps(data))\n",
        "    print(f\"Extracted and saved to GCS: {blob_name}\")\n",
        "else:\n",
        "  print(\"Failed to fetch data:\", result.status_code)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGUP7d0SswlK",
        "outputId": "1e53405f-ef0d-4b2d-9133-ce7abff54a56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformed!\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from datetime import datetime,timedelta\n",
        "spark=SparkSession.builder.appName(\"Weather_ETL\")\\\n",
        ".config(\"spark.driver.memory\",\"1g\")\\\n",
        ".config(\"spark.executor.memory\",\"1g\").getOrCreate()\n",
        "yesterday_date=(datetime.now()-timedelta(days=1)).strftime('%d-%m-%Y')\n",
        "city=\"Mumbai\"\n",
        "df=spark.read.option(\"multiline\",\"True\").json(\"weather_date-2025-10-24.json\")\n",
        "df_zip=df.select(F.arrays_zip('hourly.temperature_2m','hourly.precipitation').alias('zipped'))\n",
        "df_explode=df_zip.select(F.explode('zipped').alias (\"row\"))\n",
        "df_clean=df_explode.select(F.col('row.temperature_2m'),F.col('row.precipitation'))\n",
        "df_tranform=df_clean.agg(\n",
        "    F.round(F.max('temperature_2m'),2).alias('Max_temperature'),\n",
        "    F.round(F.min('temperature_2m'),2).alias('Min_temperature'),\n",
        "    F.round(F.avg('temperature_2m'),2).alias('Avg_temperature'),\n",
        "    F.round(F.sum('precipitation'),2).alias('Total_precipitation'),\n",
        "    F.round(F.avg('precipitation'),2).alias('Avg_precipitation')\n",
        ")\n",
        "df_final=df_tranform\\\n",
        "         .withColumn('Date',F.lit(yesterday_date))\\\n",
        "         .withColumn('City',F.lit(city))\\\n",
        "         .withColumn('Max_temperature',F.concat(F.col('Max_temperature'),F.lit('°C')))\\\n",
        "         .withColumn('Min_temperature',F.concat(F.col('Min_temperature'),F.lit('°C')))\\\n",
        "         .withColumn('Avg_temperature',F.concat(F.col('Avg_temperature'),F.lit('°C')))\\\n",
        "         .withColumn('Total_precipitation',F.concat(F.col('Total_precipitation'),F.lit('mm')))\\\n",
        "         .withColumn('Avg_precipitation',F.concat(F.col('Avg_precipitation'),F.lit('mm')))\\\n",
        "         .select('Date','City','Max_temperature','Min_temperature','Avg_temperature',\n",
        "                 'Total_precipitation','Avg_precipitation')\n",
        "df_final.coalesce(1).write.mode('overwrite').option('header',True).csv(f'Transformed_weather_data')\n",
        "print(\"Transformed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESoQqsCzYYni",
        "outputId": "648798a3-4bc9-4e11-bc25-abdd17d1b47d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Appended data to subtle-seer-472708-q3.weather_dataset.Mumbai_weather_analysis\n"
          ]
        }
      ],
      "source": [
        "from google.cloud import bigquery\n",
        "import glob\n",
        "project_id=\"your-project-id\"\n",
        "dataset_id=\"weather_dataset\"\n",
        "table_id=\"Mumbai_weather_analysis\"\n",
        "csv_directory=\"Transformed_weather_data\"\n",
        "key_path=\"your-key\"\n",
        "\n",
        "Data_schema = [\n",
        "        bigquery.SchemaField(\"Date\", \"STRING\", mode=\"REQUIRED\"),\n",
        "        bigquery.SchemaField(\"City\", \"STRING\", mode=\"REQUIRED\"),\n",
        "        bigquery.SchemaField(\"Max_temperature\", \"STRING\"),\n",
        "        bigquery.SchemaField(\"Min_temperature\", \"STRING\"),\n",
        "        bigquery.SchemaField(\"Avg_temperature\", \"STRING\"),\n",
        "        bigquery.SchemaField(\"Total_precipitation\", \"STRING\"),\n",
        "        bigquery.SchemaField(\"Avg_precipitation\", \"STRING\")\n",
        "]\n",
        "\n",
        "client=bigquery.Client.from_service_account_json(key_path)\n",
        "try:\n",
        "  client.get_dataset(dataset_id)\n",
        "except :\n",
        "  client.create_dataset(dataset_id)\n",
        "\n",
        "table_ref=f\"{project_id}.{dataset_id}.{table_id}\"\n",
        "\n",
        "csv_file=glob.glob(f\"{csv_directory}/part-*.csv\")\n",
        "if not csv_file:\n",
        "   raise FileNotFoundError(f\"No CSV found in {csv_directory}\")\n",
        "csv_file=csv_file[0]\n",
        "\n",
        "job_config = bigquery.LoadJobConfig(\n",
        "    source_format=bigquery.SourceFormat.CSV,\n",
        "    skip_leading_rows=1,\n",
        "    schema=Data_schema,\n",
        "    write_disposition=bigquery.WriteDisposition.WRITE_APPEND\n",
        ")\n",
        "with open(csv_file,'rb')as f:\n",
        "   job = client.load_table_from_file(f, table_ref, job_config=job_config)\n",
        "\n",
        "job.result()\n",

        "print(f"Data appended successfully to the table\")"
      ],
      "metadata": {
        "id": "ESoQqsCzYYni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "648798a3-4bc9-4e11-bc25-abdd17d1b47d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data appended successfully to the table"
          ]
        }
        "print(f\"Data appended successfully to the table")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
