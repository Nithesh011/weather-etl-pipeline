{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install pyspark requests google-cloud-storage google-cloud-bigquery\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iOR3lRx4tJwE",
        "outputId": "2bdcfe9f-621e-4272-e4c3-07af6252d206"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.12/dist-packages (3.38.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.38.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.25.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (1.7.1)\n",
            "Requirement already satisfied: packaging>=24.2.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (25.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.26.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.75.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (4.9.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio<2.0.0,>=1.33.2->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (4.15.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cell 2: Extract (API Fetch with GCS Backup)\n",
        "import requests\n",
        "import json\n",
        "from google.cloud import storage\n",
        "from datetime import datetime\n",
        "\n",
        "url = \"https://api.open-meteo.com/v1/forecast?latitude=19.07&longitude=72.88&daily=temperature_2m_max,temperature_2m_min,precipitation_sum&timezone=Asia/Kolkata&past_days=3\"  # Mumbai, India\n",
        "response = requests.get(url)\n",
        "if response.status_code == 200:\n",
        "    data = response.json()\n",
        "    # Save to local temp file\n",
        "    with open('weather_data.json', 'w') as f:\n",
        "        json.dump(data, f)\n",
        "    # Save to GCS for backup\n",
        "    client = storage.Client.from_service_account_json('Your-key')  # Replace with your local key path\n",
        "    bucket = client.get_bucket('your-bucket')  # Replace with your bucket\n",
        "    blob_name = f'weather_raw_{datetime.now().strftime(\"%Y-%m-%d\")}.json'\n",
        "    blob = bucket.blob(blob_name)\n",
        "    blob.upload_from_string(json.dumps(data))\n",
        "    print(f\"Extracted and saved to GCS: {blob_name}\")\n",
        "else:\n",
        "    print(\"API error:\", response.status_code)"
      ],
      "metadata": {
        "id": "JOKCc5IaJy-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23bb7d40-befc-421a-9282-9dbe590a12f7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted and saved to GCS: weather_raw_2025-09-28.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cell 3:Transform (with City and End Date Columns)\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import avg, sum, col, lit, max, min, round, concat, row_number\n",
        "from pyspark.sql.window import Window\n",
        "from datetime import datetime, timedelta\n",
        "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-11-openjdk-amd64'  # Keep as is for testing\n",
        "spark = SparkSession.builder.appName('WeatherETL').config(\"spark.driver.memory\", \"1g\").config(\"spark.executor.memory\", \"1g\").getOrCreate()\n",
        "df = spark.read.json('weather_data.json')\n",
        "df_daily = df.selectExpr(\"explode(arrays_zip(daily.time, daily.temperature_2m_max, daily.temperature_2m_min, daily.precipitation_sum)) as daily_data\")\n",
        "df_exploded = df_daily.select(\n",
        "    col(\"daily_data.time\").alias(\"date\"),\n",
        "    col(\"daily_data.temperature_2m_max\").alias(\"max_temp\"),\n",
        "    col(\"daily_data.temperature_2m_min\").alias(\"min_temp\"),\n",
        "    col(\"daily_data.precipitation_sum\").alias(\"precipitation\")\n",
        ")\n",
        "# Filter to yesterday's date\n",
        "yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "df_exploded = df_exploded.filter(col(\"date\") == yesterday)\n",
        "end_date = df_exploded.agg(max(\"date\").alias(\"end_date\")).collect()[0][\"end_date\"]\n",
        "analysis = df_exploded.agg(\n",
        "    max(\"max_temp\").alias(\"max_temp\"),\n",
        "    min(\"min_temp\").alias(\"min_temp\"),\n",
        "    sum(\"precipitation\").alias(\"total_precipitation\")\n",
        ").withColumn(\"city\", lit(\"Mumbai\")).withColumn(\"end_date\", lit(end_date))\n",
        "window_spec = Window.orderBy(lit(1))  # Dummy order to ensure row_number works\n",
        "analysis = analysis.withColumn(\"id\", row_number().over(window_spec) - 1 + 1)  # Start from 1\n",
        "analysis = analysis.select(\"id\", \"city\", \"max_temp\", \"min_temp\", \"total_precipitation\", \"end_date\") \\\n",
        "    .withColumn(\"max_temp\", concat(round(col(\"max_temp\"), 2), lit(\"°C\"))) \\\n",
        "    .withColumn(\"min_temp\", concat(round(col(\"min_temp\"), 2), lit(\"°C\"))) \\\n",
        "    .withColumn(\"total_precipitation\", concat(round(col(\"total_precipitation\"), 2), lit(\" mm\")))\n",
        "analysis.coalesce(1).write.mode('overwrite').csv('transformed_weather', header=True)\n",
        "print(\"Transformed!\")"
      ],
      "metadata": {
        "id": "wFbAEs6dJ7Yx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c6854f6-1e38-44cf-dc9b-d360d96654ab"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cell 4: Load (to BigQuery)\n",
        "from google.cloud import bigquery\n",
        "import os\n",
        "client = bigquery.Client.from_service_account_json('your-key')  # Replace with your local key path\n",
        "dataset_id = 'weather_dataset'\n",
        "try:\n",
        "    client.get_dataset(dataset_id)\n",
        "except:\n",
        "    client.create_dataset(dataset_id)\n",
        "table_id = 'your-project-id.weather_dataset.weather_analysis'  # Replace with your Project ID\n",
        "for file in os.listdir('transformed_weather'):\n",
        "    if file.startswith('part-') and file.endswith('.csv'):\n",
        "        csv_file = f'transformed_weather/{file}'\n",
        "        break\n",
        "else:\n",
        "    raise Exception(\"No CSV found in 'transformed_weather'\")\n",
        "job_config = bigquery.LoadJobConfig(\n",
        "    source_format=bigquery.SourceFormat.CSV,\n",
        "    skip_leading_rows=1,\n",
        "    autodetect=True,\n",
        "    write_disposition='WRITE_TRUNCATE'  # Overwrite to avoid duplicates\n",
        ")\n",
        "with open(csv_file, 'rb') as source_file:\n",
        "    job = client.load_table_from_file(source_file, table_id, job_config=job_config)\n",
        "job.result()\n",
        "print(\"Loaded to BigQuery!\")"
      ],
      "metadata": {
        "id": "b7Rd6_z0KDg9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "271acfb3-ae08-41ff-e4c9-079452e52a7b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded to BigQuery!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xKhm0sPBKtHR"
      },
      "execution_count": 18,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}